{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02_피마 원주민 당뇨병.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOLChs4RlR+JsLr7dbLLw2L",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/STNox/Deep-Learning/blob/master/2.%20Model/02_%ED%94%BC%EB%A7%88_%EC%9B%90%EC%A3%BC%EB%AF%BC_%EB%8B%B9%EB%87%A8%EB%B3%91.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFC17EjopUvb"
      },
      "source": [
        "# 피마 원주민 당뇨병"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzDy-8iHpQCp"
      },
      "source": [
        "import numpy as np\r\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XaR0pdbptjj"
      },
      "source": [
        "seed = 2021\r\n",
        "np.random.seed(seed)\r\n",
        "tf.random.set_seed(seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oR9cYLAUp5hO"
      },
      "source": [
        "### 데이터 전처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 177
        },
        "id": "tPVigygap46W",
        "outputId": "c9f7014b-05a0-4ef6-bda4-d8c4db8b2f8f"
      },
      "source": [
        "from google.colab import files\r\n",
        "uploaded = files.upload()\r\n",
        "filename = list(uploaded.keys())[0]\r\n",
        "Data_set = np.loadtxt(filename, delimiter=',')\r\n",
        "Data_set[:3, :]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-6c74d5f8-3085-4e86-a48b-d7e43ad67fc2\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-6c74d5f8-3085-4e86-a48b-d7e43ad67fc2\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving pima-indians-diabetes.csv to pima-indians-diabetes.csv\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  6.   , 148.   ,  72.   ,  35.   ,   0.   ,  33.6  ,   0.627,\n",
              "         50.   ,   1.   ],\n",
              "       [  1.   ,  85.   ,  66.   ,  29.   ,   0.   ,  26.6  ,   0.351,\n",
              "         31.   ,   0.   ],\n",
              "       [  8.   , 183.   ,  64.   ,   0.   ,   0.   ,  23.3  ,   0.672,\n",
              "         32.   ,   1.   ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2o3ow4PcqTMv"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\r\n",
        "scaler = StandardScaler()\r\n",
        "X_norm = scaler.fit_transform(Data_set[:, :-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BnsfVauqpMG",
        "outputId": "95db053c-5997-4697-8228-f98a6093ae9b"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_norm, Data_set[:, -1], stratify=Data_set[:, -1], random_state=seed)\r\n",
        "X_train.shape, X_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((576, 8), (192, 8))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4lwcniZq_v0"
      },
      "source": [
        "### 모델 정의, 설정, 학습, 평가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdfPbOGxq9mU"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras.layers import Dense"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cA9rBYskrN-0",
        "outputId": "93bcf1f9-407f-4e36-93e6-468b5c69d40b"
      },
      "source": [
        "model = Sequential([\r\n",
        "                    Dense(12, input_shape=(8,), activation='relu'),\r\n",
        "                    Dense(8, activation='relu'),\r\n",
        "                    Dense(1, activation='sigmoid')\r\n",
        "])\r\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 12)                108       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 8)                 104       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 221\n",
            "Trainable params: 221\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oc4BgMfVsBdJ"
      },
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_x9wc9iWsR3Q",
        "outputId": "0dd37e52-a7ce-480b-e5b1-688c61a85f57"
      },
      "source": [
        "history = model.fit(X_train, y_train, epochs=200, validation_split=0.2, batch_size=20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "23/23 [==============================] - 1s 17ms/step - loss: 0.6485 - accuracy: 0.6219 - val_loss: 0.5971 - val_accuracy: 0.6379\n",
            "Epoch 2/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.6003 - accuracy: 0.6959 - val_loss: 0.5717 - val_accuracy: 0.6638\n",
            "Epoch 3/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.5720 - accuracy: 0.6904 - val_loss: 0.5540 - val_accuracy: 0.6293\n",
            "Epoch 4/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.5450 - accuracy: 0.7372 - val_loss: 0.5456 - val_accuracy: 0.6466\n",
            "Epoch 5/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.5559 - accuracy: 0.7276 - val_loss: 0.5397 - val_accuracy: 0.6810\n",
            "Epoch 6/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.5248 - accuracy: 0.7505 - val_loss: 0.5348 - val_accuracy: 0.6724\n",
            "Epoch 7/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.5081 - accuracy: 0.7467 - val_loss: 0.5307 - val_accuracy: 0.6983\n",
            "Epoch 8/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4947 - accuracy: 0.7867 - val_loss: 0.5306 - val_accuracy: 0.6983\n",
            "Epoch 9/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7659 - val_loss: 0.5273 - val_accuracy: 0.7155\n",
            "Epoch 10/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4962 - accuracy: 0.7627 - val_loss: 0.5257 - val_accuracy: 0.6897\n",
            "Epoch 11/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4785 - accuracy: 0.7795 - val_loss: 0.5277 - val_accuracy: 0.6983\n",
            "Epoch 12/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4704 - accuracy: 0.7836 - val_loss: 0.5286 - val_accuracy: 0.6983\n",
            "Epoch 13/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4522 - accuracy: 0.8132 - val_loss: 0.5278 - val_accuracy: 0.6897\n",
            "Epoch 14/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4824 - accuracy: 0.7753 - val_loss: 0.5281 - val_accuracy: 0.6897\n",
            "Epoch 15/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4466 - accuracy: 0.7901 - val_loss: 0.5309 - val_accuracy: 0.6983\n",
            "Epoch 16/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4661 - accuracy: 0.8041 - val_loss: 0.5310 - val_accuracy: 0.6897\n",
            "Epoch 17/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4648 - accuracy: 0.7870 - val_loss: 0.5341 - val_accuracy: 0.6983\n",
            "Epoch 18/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4588 - accuracy: 0.8058 - val_loss: 0.5331 - val_accuracy: 0.6897\n",
            "Epoch 19/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4554 - accuracy: 0.7849 - val_loss: 0.5376 - val_accuracy: 0.7069\n",
            "Epoch 20/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.4358 - accuracy: 0.8059 - val_loss: 0.5376 - val_accuracy: 0.7069\n",
            "Epoch 21/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4782 - accuracy: 0.7643 - val_loss: 0.5375 - val_accuracy: 0.7069\n",
            "Epoch 22/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.3828 - accuracy: 0.8378 - val_loss: 0.5403 - val_accuracy: 0.7069\n",
            "Epoch 23/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4712 - accuracy: 0.7600 - val_loss: 0.5401 - val_accuracy: 0.7069\n",
            "Epoch 24/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4487 - accuracy: 0.7850 - val_loss: 0.5405 - val_accuracy: 0.6983\n",
            "Epoch 25/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4131 - accuracy: 0.8114 - val_loss: 0.5451 - val_accuracy: 0.7069\n",
            "Epoch 26/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4343 - accuracy: 0.8063 - val_loss: 0.5474 - val_accuracy: 0.7155\n",
            "Epoch 27/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.4614 - accuracy: 0.7884 - val_loss: 0.5445 - val_accuracy: 0.7328\n",
            "Epoch 28/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4100 - accuracy: 0.8206 - val_loss: 0.5494 - val_accuracy: 0.7069\n",
            "Epoch 29/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4354 - accuracy: 0.7808 - val_loss: 0.5486 - val_accuracy: 0.7069\n",
            "Epoch 30/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4236 - accuracy: 0.8110 - val_loss: 0.5510 - val_accuracy: 0.7069\n",
            "Epoch 31/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4064 - accuracy: 0.8192 - val_loss: 0.5529 - val_accuracy: 0.7069\n",
            "Epoch 32/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4037 - accuracy: 0.8078 - val_loss: 0.5530 - val_accuracy: 0.7069\n",
            "Epoch 33/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.3948 - accuracy: 0.8167 - val_loss: 0.5546 - val_accuracy: 0.7069\n",
            "Epoch 34/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4235 - accuracy: 0.7991 - val_loss: 0.5550 - val_accuracy: 0.7069\n",
            "Epoch 35/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.3833 - accuracy: 0.8370 - val_loss: 0.5570 - val_accuracy: 0.7069\n",
            "Epoch 36/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4423 - accuracy: 0.7823 - val_loss: 0.5585 - val_accuracy: 0.7069\n",
            "Epoch 37/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4335 - accuracy: 0.7953 - val_loss: 0.5572 - val_accuracy: 0.7155\n",
            "Epoch 38/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4008 - accuracy: 0.8125 - val_loss: 0.5653 - val_accuracy: 0.7069\n",
            "Epoch 39/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.3985 - accuracy: 0.8089 - val_loss: 0.5608 - val_accuracy: 0.7069\n",
            "Epoch 40/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4103 - accuracy: 0.8173 - val_loss: 0.5631 - val_accuracy: 0.7069\n",
            "Epoch 41/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.3987 - accuracy: 0.8171 - val_loss: 0.5640 - val_accuracy: 0.7069\n",
            "Epoch 42/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.3742 - accuracy: 0.8219 - val_loss: 0.5650 - val_accuracy: 0.7241\n",
            "Epoch 43/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4198 - accuracy: 0.8031 - val_loss: 0.5643 - val_accuracy: 0.7328\n",
            "Epoch 44/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4149 - accuracy: 0.7998 - val_loss: 0.5657 - val_accuracy: 0.7328\n",
            "Epoch 45/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4060 - accuracy: 0.8106 - val_loss: 0.5677 - val_accuracy: 0.7328\n",
            "Epoch 46/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3831 - accuracy: 0.8165 - val_loss: 0.5703 - val_accuracy: 0.7328\n",
            "Epoch 47/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4183 - accuracy: 0.8071 - val_loss: 0.5699 - val_accuracy: 0.7328\n",
            "Epoch 48/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4182 - accuracy: 0.7939 - val_loss: 0.5694 - val_accuracy: 0.7328\n",
            "Epoch 49/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4205 - accuracy: 0.7953 - val_loss: 0.5711 - val_accuracy: 0.7328\n",
            "Epoch 50/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4048 - accuracy: 0.7959 - val_loss: 0.5714 - val_accuracy: 0.7328\n",
            "Epoch 51/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.3859 - accuracy: 0.8180 - val_loss: 0.5722 - val_accuracy: 0.7328\n",
            "Epoch 52/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.3756 - accuracy: 0.8343 - val_loss: 0.5751 - val_accuracy: 0.7241\n",
            "Epoch 53/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.3988 - accuracy: 0.8117 - val_loss: 0.5770 - val_accuracy: 0.7241\n",
            "Epoch 54/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.3924 - accuracy: 0.8252 - val_loss: 0.5756 - val_accuracy: 0.7241\n",
            "Epoch 55/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4308 - accuracy: 0.7919 - val_loss: 0.5759 - val_accuracy: 0.7241\n",
            "Epoch 56/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3773 - accuracy: 0.8316 - val_loss: 0.5813 - val_accuracy: 0.7241\n",
            "Epoch 57/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4018 - accuracy: 0.8311 - val_loss: 0.5805 - val_accuracy: 0.7241\n",
            "Epoch 58/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4011 - accuracy: 0.8002 - val_loss: 0.5795 - val_accuracy: 0.7241\n",
            "Epoch 59/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4023 - accuracy: 0.8004 - val_loss: 0.5807 - val_accuracy: 0.7241\n",
            "Epoch 60/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.3949 - accuracy: 0.8121 - val_loss: 0.5841 - val_accuracy: 0.7241\n",
            "Epoch 61/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3868 - accuracy: 0.8141 - val_loss: 0.5859 - val_accuracy: 0.7241\n",
            "Epoch 62/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.3702 - accuracy: 0.8385 - val_loss: 0.5851 - val_accuracy: 0.7241\n",
            "Epoch 63/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.3685 - accuracy: 0.8398 - val_loss: 0.5878 - val_accuracy: 0.7241\n",
            "Epoch 64/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.3694 - accuracy: 0.8361 - val_loss: 0.5868 - val_accuracy: 0.7328\n",
            "Epoch 65/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.3613 - accuracy: 0.8521 - val_loss: 0.5889 - val_accuracy: 0.7328\n",
            "Epoch 66/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.3756 - accuracy: 0.8336 - val_loss: 0.5892 - val_accuracy: 0.7328\n",
            "Epoch 67/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.3878 - accuracy: 0.8192 - val_loss: 0.5939 - val_accuracy: 0.7241\n",
            "Epoch 68/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.3618 - accuracy: 0.8261 - val_loss: 0.5942 - val_accuracy: 0.7241\n",
            "Epoch 69/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4054 - accuracy: 0.8025 - val_loss: 0.5946 - val_accuracy: 0.7241\n",
            "Epoch 70/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.3911 - accuracy: 0.8145 - val_loss: 0.5954 - val_accuracy: 0.7328\n",
            "Epoch 71/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.3903 - accuracy: 0.8069 - val_loss: 0.5950 - val_accuracy: 0.7328\n",
            "Epoch 72/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.3698 - accuracy: 0.8362 - val_loss: 0.5989 - val_accuracy: 0.7328\n",
            "Epoch 73/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3532 - accuracy: 0.8455 - val_loss: 0.6004 - val_accuracy: 0.7241\n",
            "Epoch 74/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.3646 - accuracy: 0.8258 - val_loss: 0.5970 - val_accuracy: 0.7328\n",
            "Epoch 75/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.3671 - accuracy: 0.8171 - val_loss: 0.5981 - val_accuracy: 0.7241\n",
            "Epoch 76/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.3997 - accuracy: 0.8155 - val_loss: 0.5955 - val_accuracy: 0.7328\n",
            "Epoch 77/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.3768 - accuracy: 0.8194 - val_loss: 0.6037 - val_accuracy: 0.7241\n",
            "Epoch 78/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4011 - accuracy: 0.7934 - val_loss: 0.5999 - val_accuracy: 0.7328\n",
            "Epoch 79/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.3866 - accuracy: 0.8194 - val_loss: 0.6015 - val_accuracy: 0.7328\n",
            "Epoch 80/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.3395 - accuracy: 0.8559 - val_loss: 0.6058 - val_accuracy: 0.7328\n",
            "Epoch 81/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.3692 - accuracy: 0.8259 - val_loss: 0.6040 - val_accuracy: 0.7328\n",
            "Epoch 82/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.3587 - accuracy: 0.8419 - val_loss: 0.6034 - val_accuracy: 0.7328\n",
            "Epoch 83/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.3440 - accuracy: 0.8538 - val_loss: 0.6072 - val_accuracy: 0.7328\n",
            "Epoch 84/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3436 - accuracy: 0.8514 - val_loss: 0.6096 - val_accuracy: 0.7328\n",
            "Epoch 85/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.3610 - accuracy: 0.8430 - val_loss: 0.6080 - val_accuracy: 0.7328\n",
            "Epoch 86/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.3605 - accuracy: 0.8272 - val_loss: 0.6119 - val_accuracy: 0.7328\n",
            "Epoch 87/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.3575 - accuracy: 0.8508 - val_loss: 0.6106 - val_accuracy: 0.7241\n",
            "Epoch 88/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.3451 - accuracy: 0.8657 - val_loss: 0.6166 - val_accuracy: 0.7241\n",
            "Epoch 89/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.3642 - accuracy: 0.8322 - val_loss: 0.6143 - val_accuracy: 0.7328\n",
            "Epoch 90/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.3459 - accuracy: 0.8456 - val_loss: 0.6106 - val_accuracy: 0.7328\n",
            "Epoch 91/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.3220 - accuracy: 0.8831 - val_loss: 0.6181 - val_accuracy: 0.7241\n",
            "Epoch 92/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.3656 - accuracy: 0.8539 - val_loss: 0.6170 - val_accuracy: 0.7328\n",
            "Epoch 93/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.3777 - accuracy: 0.8510 - val_loss: 0.6159 - val_accuracy: 0.7328\n",
            "Epoch 94/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3370 - accuracy: 0.8623 - val_loss: 0.6248 - val_accuracy: 0.7241\n",
            "Epoch 95/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4012 - accuracy: 0.8140 - val_loss: 0.6215 - val_accuracy: 0.7328\n",
            "Epoch 96/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.3433 - accuracy: 0.8600 - val_loss: 0.6272 - val_accuracy: 0.7328\n",
            "Epoch 97/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.3343 - accuracy: 0.8706 - val_loss: 0.6245 - val_accuracy: 0.7328\n",
            "Epoch 98/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3356 - accuracy: 0.8738 - val_loss: 0.6284 - val_accuracy: 0.7328\n",
            "Epoch 99/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.3936 - accuracy: 0.8121 - val_loss: 0.6273 - val_accuracy: 0.7328\n",
            "Epoch 100/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.3407 - accuracy: 0.8638 - val_loss: 0.6296 - val_accuracy: 0.7241\n",
            "Epoch 101/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.3497 - accuracy: 0.8442 - val_loss: 0.6329 - val_accuracy: 0.7241\n",
            "Epoch 102/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.3249 - accuracy: 0.8636 - val_loss: 0.6327 - val_accuracy: 0.7328\n",
            "Epoch 103/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.3361 - accuracy: 0.8589 - val_loss: 0.6346 - val_accuracy: 0.7241\n",
            "Epoch 104/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3302 - accuracy: 0.8524 - val_loss: 0.6349 - val_accuracy: 0.7328\n",
            "Epoch 105/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.3544 - accuracy: 0.8578 - val_loss: 0.6404 - val_accuracy: 0.7241\n",
            "Epoch 106/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.3973 - accuracy: 0.8308 - val_loss: 0.6357 - val_accuracy: 0.7328\n",
            "Epoch 107/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.3345 - accuracy: 0.8553 - val_loss: 0.6430 - val_accuracy: 0.7241\n",
            "Epoch 108/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3293 - accuracy: 0.8666 - val_loss: 0.6439 - val_accuracy: 0.7241\n",
            "Epoch 109/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.3729 - accuracy: 0.8276 - val_loss: 0.6408 - val_accuracy: 0.7241\n",
            "Epoch 110/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.3147 - accuracy: 0.8756 - val_loss: 0.6505 - val_accuracy: 0.7328\n",
            "Epoch 111/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.3397 - accuracy: 0.8476 - val_loss: 0.6427 - val_accuracy: 0.7241\n",
            "Epoch 112/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.3494 - accuracy: 0.8529 - val_loss: 0.6534 - val_accuracy: 0.7328\n",
            "Epoch 113/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3311 - accuracy: 0.8725 - val_loss: 0.6508 - val_accuracy: 0.7328\n",
            "Epoch 114/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.3165 - accuracy: 0.8559 - val_loss: 0.6554 - val_accuracy: 0.7241\n",
            "Epoch 115/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.3122 - accuracy: 0.8691 - val_loss: 0.6520 - val_accuracy: 0.7241\n",
            "Epoch 116/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3179 - accuracy: 0.8791 - val_loss: 0.6562 - val_accuracy: 0.7241\n",
            "Epoch 117/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.3008 - accuracy: 0.8774 - val_loss: 0.6603 - val_accuracy: 0.7241\n",
            "Epoch 118/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.3226 - accuracy: 0.8699 - val_loss: 0.6539 - val_accuracy: 0.7241\n",
            "Epoch 119/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3435 - accuracy: 0.8485 - val_loss: 0.6603 - val_accuracy: 0.7241\n",
            "Epoch 120/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.3599 - accuracy: 0.8389 - val_loss: 0.6637 - val_accuracy: 0.7328\n",
            "Epoch 121/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.3232 - accuracy: 0.8551 - val_loss: 0.6643 - val_accuracy: 0.7241\n",
            "Epoch 122/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.3206 - accuracy: 0.8724 - val_loss: 0.6615 - val_accuracy: 0.7241\n",
            "Epoch 123/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.3188 - accuracy: 0.8805 - val_loss: 0.6682 - val_accuracy: 0.7241\n",
            "Epoch 124/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.3792 - accuracy: 0.8444 - val_loss: 0.6646 - val_accuracy: 0.7328\n",
            "Epoch 125/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.3072 - accuracy: 0.8777 - val_loss: 0.6699 - val_accuracy: 0.7241\n",
            "Epoch 126/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.3223 - accuracy: 0.8646 - val_loss: 0.6697 - val_accuracy: 0.7414\n",
            "Epoch 127/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3400 - accuracy: 0.8604 - val_loss: 0.6733 - val_accuracy: 0.7241\n",
            "Epoch 128/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.3190 - accuracy: 0.8892 - val_loss: 0.6727 - val_accuracy: 0.7414\n",
            "Epoch 129/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.3347 - accuracy: 0.8467 - val_loss: 0.6761 - val_accuracy: 0.7241\n",
            "Epoch 130/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.3240 - accuracy: 0.8478 - val_loss: 0.6776 - val_accuracy: 0.7414\n",
            "Epoch 131/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2930 - accuracy: 0.8819 - val_loss: 0.6767 - val_accuracy: 0.7328\n",
            "Epoch 132/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2936 - accuracy: 0.8831 - val_loss: 0.6819 - val_accuracy: 0.7328\n",
            "Epoch 133/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.3184 - accuracy: 0.8722 - val_loss: 0.6796 - val_accuracy: 0.7414\n",
            "Epoch 134/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.3695 - accuracy: 0.8417 - val_loss: 0.6828 - val_accuracy: 0.7414\n",
            "Epoch 135/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2949 - accuracy: 0.8881 - val_loss: 0.6842 - val_accuracy: 0.7328\n",
            "Epoch 136/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3039 - accuracy: 0.8798 - val_loss: 0.6881 - val_accuracy: 0.7414\n",
            "Epoch 137/200\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2984 - accuracy: 0.8877 - val_loss: 0.6859 - val_accuracy: 0.7414\n",
            "Epoch 138/200\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.3137 - accuracy: 0.8669 - val_loss: 0.6909 - val_accuracy: 0.7328\n",
            "Epoch 139/200\n",
            "23/23 [==============================] - 1s 26ms/step - loss: 0.2826 - accuracy: 0.8965 - val_loss: 0.6911 - val_accuracy: 0.7414\n",
            "Epoch 140/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2740 - accuracy: 0.9005 - val_loss: 0.6932 - val_accuracy: 0.7414\n",
            "Epoch 141/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3059 - accuracy: 0.8789 - val_loss: 0.6950 - val_accuracy: 0.7328\n",
            "Epoch 142/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2970 - accuracy: 0.8833 - val_loss: 0.6944 - val_accuracy: 0.7414\n",
            "Epoch 143/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2925 - accuracy: 0.8820 - val_loss: 0.7026 - val_accuracy: 0.7500\n",
            "Epoch 144/200\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.3142 - accuracy: 0.8787 - val_loss: 0.6996 - val_accuracy: 0.7414\n",
            "Epoch 145/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3302 - accuracy: 0.8596 - val_loss: 0.7062 - val_accuracy: 0.7414\n",
            "Epoch 146/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.3315 - accuracy: 0.8604 - val_loss: 0.7013 - val_accuracy: 0.7414\n",
            "Epoch 147/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.3251 - accuracy: 0.8885 - val_loss: 0.7058 - val_accuracy: 0.7414\n",
            "Epoch 148/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.3284 - accuracy: 0.8628 - val_loss: 0.7076 - val_accuracy: 0.7328\n",
            "Epoch 149/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2809 - accuracy: 0.8893 - val_loss: 0.7137 - val_accuracy: 0.7328\n",
            "Epoch 150/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3483 - accuracy: 0.8555 - val_loss: 0.7104 - val_accuracy: 0.7414\n",
            "Epoch 151/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.2796 - accuracy: 0.9056 - val_loss: 0.7126 - val_accuracy: 0.7328\n",
            "Epoch 152/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.3016 - accuracy: 0.8809 - val_loss: 0.7150 - val_accuracy: 0.7414\n",
            "Epoch 153/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2826 - accuracy: 0.8942 - val_loss: 0.7171 - val_accuracy: 0.7414\n",
            "Epoch 154/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2614 - accuracy: 0.9040 - val_loss: 0.7191 - val_accuracy: 0.7328\n",
            "Epoch 155/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.3146 - accuracy: 0.8655 - val_loss: 0.7206 - val_accuracy: 0.7328\n",
            "Epoch 156/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.3337 - accuracy: 0.8541 - val_loss: 0.7249 - val_accuracy: 0.7328\n",
            "Epoch 157/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2868 - accuracy: 0.8883 - val_loss: 0.7285 - val_accuracy: 0.7328\n",
            "Epoch 158/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2977 - accuracy: 0.8878 - val_loss: 0.7283 - val_accuracy: 0.7328\n",
            "Epoch 159/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.3213 - accuracy: 0.8735 - val_loss: 0.7281 - val_accuracy: 0.7328\n",
            "Epoch 160/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2918 - accuracy: 0.8929 - val_loss: 0.7317 - val_accuracy: 0.7328\n",
            "Epoch 161/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.3097 - accuracy: 0.8768 - val_loss: 0.7327 - val_accuracy: 0.7328\n",
            "Epoch 162/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.3240 - accuracy: 0.8734 - val_loss: 0.7388 - val_accuracy: 0.7328\n",
            "Epoch 163/200\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.3190 - accuracy: 0.8659 - val_loss: 0.7412 - val_accuracy: 0.7328\n",
            "Epoch 164/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2891 - accuracy: 0.9069 - val_loss: 0.7379 - val_accuracy: 0.7328\n",
            "Epoch 165/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.3019 - accuracy: 0.8880 - val_loss: 0.7445 - val_accuracy: 0.7328\n",
            "Epoch 166/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2744 - accuracy: 0.8988 - val_loss: 0.7409 - val_accuracy: 0.7328\n",
            "Epoch 167/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3010 - accuracy: 0.8857 - val_loss: 0.7458 - val_accuracy: 0.7328\n",
            "Epoch 168/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3137 - accuracy: 0.8772 - val_loss: 0.7472 - val_accuracy: 0.7328\n",
            "Epoch 169/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.3099 - accuracy: 0.8866 - val_loss: 0.7529 - val_accuracy: 0.7328\n",
            "Epoch 170/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2680 - accuracy: 0.9054 - val_loss: 0.7533 - val_accuracy: 0.7328\n",
            "Epoch 171/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.2960 - accuracy: 0.8831 - val_loss: 0.7538 - val_accuracy: 0.7328\n",
            "Epoch 172/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2977 - accuracy: 0.8746 - val_loss: 0.7557 - val_accuracy: 0.7328\n",
            "Epoch 173/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.3070 - accuracy: 0.8728 - val_loss: 0.7551 - val_accuracy: 0.7328\n",
            "Epoch 174/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2835 - accuracy: 0.9005 - val_loss: 0.7593 - val_accuracy: 0.7328\n",
            "Epoch 175/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3356 - accuracy: 0.8679 - val_loss: 0.7609 - val_accuracy: 0.7328\n",
            "Epoch 176/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2928 - accuracy: 0.8889 - val_loss: 0.7640 - val_accuracy: 0.7328\n",
            "Epoch 177/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.3306 - accuracy: 0.8633 - val_loss: 0.7683 - val_accuracy: 0.7328\n",
            "Epoch 178/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.3018 - accuracy: 0.8791 - val_loss: 0.7702 - val_accuracy: 0.7414\n",
            "Epoch 179/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2617 - accuracy: 0.8872 - val_loss: 0.7683 - val_accuracy: 0.7328\n",
            "Epoch 180/200\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.2773 - accuracy: 0.8861 - val_loss: 0.7816 - val_accuracy: 0.7069\n",
            "Epoch 181/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.3008 - accuracy: 0.8898 - val_loss: 0.7737 - val_accuracy: 0.7414\n",
            "Epoch 182/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2883 - accuracy: 0.8916 - val_loss: 0.7754 - val_accuracy: 0.7414\n",
            "Epoch 183/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.3313 - accuracy: 0.8490 - val_loss: 0.7737 - val_accuracy: 0.7414\n",
            "Epoch 184/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2737 - accuracy: 0.8907 - val_loss: 0.7824 - val_accuracy: 0.7328\n",
            "Epoch 185/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2775 - accuracy: 0.8839 - val_loss: 0.7825 - val_accuracy: 0.7328\n",
            "Epoch 186/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.3018 - accuracy: 0.8730 - val_loss: 0.7838 - val_accuracy: 0.7328\n",
            "Epoch 187/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2588 - accuracy: 0.9056 - val_loss: 0.7848 - val_accuracy: 0.7500\n",
            "Epoch 188/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2706 - accuracy: 0.9029 - val_loss: 0.7887 - val_accuracy: 0.7414\n",
            "Epoch 189/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2495 - accuracy: 0.9020 - val_loss: 0.7875 - val_accuracy: 0.7328\n",
            "Epoch 190/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2660 - accuracy: 0.8902 - val_loss: 0.7903 - val_accuracy: 0.7328\n",
            "Epoch 191/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2998 - accuracy: 0.8778 - val_loss: 0.7976 - val_accuracy: 0.7414\n",
            "Epoch 192/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2815 - accuracy: 0.8821 - val_loss: 0.7930 - val_accuracy: 0.7414\n",
            "Epoch 193/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2944 - accuracy: 0.8820 - val_loss: 0.8024 - val_accuracy: 0.7069\n",
            "Epoch 194/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2777 - accuracy: 0.8868 - val_loss: 0.7992 - val_accuracy: 0.7328\n",
            "Epoch 195/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2547 - accuracy: 0.9206 - val_loss: 0.8022 - val_accuracy: 0.7241\n",
            "Epoch 196/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2323 - accuracy: 0.9142 - val_loss: 0.8018 - val_accuracy: 0.7241\n",
            "Epoch 197/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2413 - accuracy: 0.9037 - val_loss: 0.8070 - val_accuracy: 0.7155\n",
            "Epoch 198/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2999 - accuracy: 0.8794 - val_loss: 0.8090 - val_accuracy: 0.7241\n",
            "Epoch 199/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2843 - accuracy: 0.8799 - val_loss: 0.8099 - val_accuracy: 0.7328\n",
            "Epoch 200/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2814 - accuracy: 0.8900 - val_loss: 0.8126 - val_accuracy: 0.7241\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkjTuf3utCbk",
        "outputId": "b9ff1567-1734-4b66-b8a9-5b62a2d7211b"
      },
      "source": [
        "acc = model.evaluate(X_test, y_test)\r\n",
        "acc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6/6 [==============================] - 0s 2ms/step - loss: 0.5618 - accuracy: 0.7812\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5617662668228149, 0.78125]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNlhX6vltP6O"
      },
      "source": [
        "### 테스트"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_25bfT1atK0j",
        "outputId": "4f8e9444-388c-41c7-a3e8-8ed19fd03a67"
      },
      "source": [
        "index = 10\r\n",
        "test_data = X_test[index, :].reshape(1, -1)\r\n",
        "test_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.54791859,  2.38188392,  0.04624525,  4.92186584, -0.69289057,\n",
              "         0.34362394,  0.31144581,  2.44704844]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKbKSvVttXC2",
        "outputId": "19ea7234-e97b-4689-ba59-408cd0b43571"
      },
      "source": [
        "label = y_test[index]\r\n",
        "int(label)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wk63J65mtcq3",
        "outputId": "0589703f-5a99-48aa-8f18-be2a442ceb05"
      },
      "source": [
        "pred = model.predict(test_data)\r\n",
        "pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.8747372]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00FYqb2qtget",
        "outputId": "82b951f8-5327-4c37-ce09-2721e947dc52"
      },
      "source": [
        "int(pred[0][0] > 0.5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yeb2_XtYyqfW"
      },
      "source": [
        "### 은닉층 추가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEsrEkdmyqKf",
        "outputId": "5a812764-da21-444d-fea6-6015b8d1a2ee"
      },
      "source": [
        "model2 = Sequential([\r\n",
        "                     Dense(24, input_shape=(8, ), activation='relu'),\r\n",
        "                     Dense(12, activation='relu'),\r\n",
        "                     Dense(8, activation='relu'),\r\n",
        "                     Dense(1, activation='sigmoid')\r\n",
        "])\r\n",
        "model2.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_7 (Dense)              (None, 24)                216       \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 12)                300       \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 8)                 104       \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 629\n",
            "Trainable params: 629\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DVIQRiBzReB"
      },
      "source": [
        "model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymecWkgUzc3i",
        "outputId": "76b8d583-fa94-4801-acc1-1563b5c0e231"
      },
      "source": [
        "history = model.fit(X_train, y_train, batch_size=20, epochs=200, validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2779 - accuracy: 0.8870 - val_loss: 0.8145 - val_accuracy: 0.7155\n",
            "Epoch 2/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2788 - accuracy: 0.8870 - val_loss: 0.8225 - val_accuracy: 0.6983\n",
            "Epoch 3/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2770 - accuracy: 0.8913 - val_loss: 0.8137 - val_accuracy: 0.7241\n",
            "Epoch 4/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2761 - accuracy: 0.8913 - val_loss: 0.8173 - val_accuracy: 0.7241\n",
            "Epoch 5/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2747 - accuracy: 0.8913 - val_loss: 0.8222 - val_accuracy: 0.6983\n",
            "Epoch 6/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2754 - accuracy: 0.8935 - val_loss: 0.8271 - val_accuracy: 0.7069\n",
            "Epoch 7/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2743 - accuracy: 0.8891 - val_loss: 0.8219 - val_accuracy: 0.7241\n",
            "Epoch 8/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2741 - accuracy: 0.8891 - val_loss: 0.8260 - val_accuracy: 0.7155\n",
            "Epoch 9/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2727 - accuracy: 0.8935 - val_loss: 0.8253 - val_accuracy: 0.7155\n",
            "Epoch 10/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2737 - accuracy: 0.9022 - val_loss: 0.8242 - val_accuracy: 0.7241\n",
            "Epoch 11/200\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.2724 - accuracy: 0.8913 - val_loss: 0.8329 - val_accuracy: 0.7155\n",
            "Epoch 12/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2719 - accuracy: 0.8913 - val_loss: 0.8344 - val_accuracy: 0.6983\n",
            "Epoch 13/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2716 - accuracy: 0.8913 - val_loss: 0.8320 - val_accuracy: 0.7155\n",
            "Epoch 14/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2713 - accuracy: 0.8913 - val_loss: 0.8340 - val_accuracy: 0.7155\n",
            "Epoch 15/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2705 - accuracy: 0.8957 - val_loss: 0.8389 - val_accuracy: 0.7155\n",
            "Epoch 16/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2693 - accuracy: 0.8957 - val_loss: 0.8398 - val_accuracy: 0.7155\n",
            "Epoch 17/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2699 - accuracy: 0.8891 - val_loss: 0.8431 - val_accuracy: 0.6897\n",
            "Epoch 18/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2685 - accuracy: 0.8957 - val_loss: 0.8321 - val_accuracy: 0.7155\n",
            "Epoch 19/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2697 - accuracy: 0.8913 - val_loss: 0.8470 - val_accuracy: 0.6983\n",
            "Epoch 20/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2681 - accuracy: 0.8957 - val_loss: 0.8453 - val_accuracy: 0.7155\n",
            "Epoch 21/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2670 - accuracy: 0.8957 - val_loss: 0.8439 - val_accuracy: 0.7069\n",
            "Epoch 22/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2664 - accuracy: 0.8978 - val_loss: 0.8475 - val_accuracy: 0.7069\n",
            "Epoch 23/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2662 - accuracy: 0.8978 - val_loss: 0.8416 - val_accuracy: 0.7155\n",
            "Epoch 24/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2651 - accuracy: 0.8935 - val_loss: 0.8467 - val_accuracy: 0.7155\n",
            "Epoch 25/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2648 - accuracy: 0.8957 - val_loss: 0.8503 - val_accuracy: 0.7069\n",
            "Epoch 26/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2650 - accuracy: 0.8957 - val_loss: 0.8588 - val_accuracy: 0.6897\n",
            "Epoch 27/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2655 - accuracy: 0.9043 - val_loss: 0.8489 - val_accuracy: 0.7069\n",
            "Epoch 28/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2626 - accuracy: 0.9000 - val_loss: 0.8639 - val_accuracy: 0.6897\n",
            "Epoch 29/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2621 - accuracy: 0.8957 - val_loss: 0.8582 - val_accuracy: 0.6983\n",
            "Epoch 30/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2622 - accuracy: 0.8978 - val_loss: 0.8665 - val_accuracy: 0.6983\n",
            "Epoch 31/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2619 - accuracy: 0.8978 - val_loss: 0.8596 - val_accuracy: 0.6983\n",
            "Epoch 32/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2609 - accuracy: 0.8978 - val_loss: 0.8651 - val_accuracy: 0.6983\n",
            "Epoch 33/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2604 - accuracy: 0.8978 - val_loss: 0.8630 - val_accuracy: 0.7069\n",
            "Epoch 34/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2599 - accuracy: 0.9022 - val_loss: 0.8655 - val_accuracy: 0.6983\n",
            "Epoch 35/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2598 - accuracy: 0.9022 - val_loss: 0.8698 - val_accuracy: 0.6983\n",
            "Epoch 36/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2586 - accuracy: 0.8978 - val_loss: 0.8722 - val_accuracy: 0.6983\n",
            "Epoch 37/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2583 - accuracy: 0.9022 - val_loss: 0.8684 - val_accuracy: 0.6983\n",
            "Epoch 38/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2578 - accuracy: 0.8978 - val_loss: 0.8777 - val_accuracy: 0.6897\n",
            "Epoch 39/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2569 - accuracy: 0.9043 - val_loss: 0.8720 - val_accuracy: 0.6983\n",
            "Epoch 40/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2560 - accuracy: 0.9000 - val_loss: 0.8804 - val_accuracy: 0.6983\n",
            "Epoch 41/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2552 - accuracy: 0.9022 - val_loss: 0.8799 - val_accuracy: 0.6983\n",
            "Epoch 42/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2560 - accuracy: 0.8935 - val_loss: 0.8839 - val_accuracy: 0.6983\n",
            "Epoch 43/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2541 - accuracy: 0.9043 - val_loss: 0.8807 - val_accuracy: 0.6983\n",
            "Epoch 44/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2536 - accuracy: 0.9065 - val_loss: 0.8836 - val_accuracy: 0.6983\n",
            "Epoch 45/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2529 - accuracy: 0.9022 - val_loss: 0.8911 - val_accuracy: 0.6897\n",
            "Epoch 46/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2530 - accuracy: 0.8978 - val_loss: 0.8929 - val_accuracy: 0.6897\n",
            "Epoch 47/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2514 - accuracy: 0.9000 - val_loss: 0.8899 - val_accuracy: 0.6983\n",
            "Epoch 48/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2513 - accuracy: 0.9087 - val_loss: 0.8926 - val_accuracy: 0.6897\n",
            "Epoch 49/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2512 - accuracy: 0.8978 - val_loss: 0.8956 - val_accuracy: 0.6983\n",
            "Epoch 50/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2504 - accuracy: 0.9022 - val_loss: 0.8980 - val_accuracy: 0.6983\n",
            "Epoch 51/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2489 - accuracy: 0.9043 - val_loss: 0.8962 - val_accuracy: 0.6897\n",
            "Epoch 52/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2488 - accuracy: 0.9043 - val_loss: 0.9029 - val_accuracy: 0.6897\n",
            "Epoch 53/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2487 - accuracy: 0.9065 - val_loss: 0.9048 - val_accuracy: 0.6897\n",
            "Epoch 54/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2479 - accuracy: 0.9000 - val_loss: 0.9004 - val_accuracy: 0.6983\n",
            "Epoch 55/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2475 - accuracy: 0.9065 - val_loss: 0.9011 - val_accuracy: 0.6983\n",
            "Epoch 56/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2482 - accuracy: 0.8935 - val_loss: 0.9122 - val_accuracy: 0.6897\n",
            "Epoch 57/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2458 - accuracy: 0.9043 - val_loss: 0.9022 - val_accuracy: 0.6983\n",
            "Epoch 58/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2456 - accuracy: 0.9065 - val_loss: 0.9108 - val_accuracy: 0.6897\n",
            "Epoch 59/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.2455 - accuracy: 0.9109 - val_loss: 0.9082 - val_accuracy: 0.6983\n",
            "Epoch 60/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2445 - accuracy: 0.9065 - val_loss: 0.9151 - val_accuracy: 0.6897\n",
            "Epoch 61/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2443 - accuracy: 0.9109 - val_loss: 0.9171 - val_accuracy: 0.6983\n",
            "Epoch 62/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2432 - accuracy: 0.9087 - val_loss: 0.9154 - val_accuracy: 0.6983\n",
            "Epoch 63/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2438 - accuracy: 0.9000 - val_loss: 0.9241 - val_accuracy: 0.6897\n",
            "Epoch 64/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2429 - accuracy: 0.9022 - val_loss: 0.9164 - val_accuracy: 0.6983\n",
            "Epoch 65/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2425 - accuracy: 0.9043 - val_loss: 0.9169 - val_accuracy: 0.6983\n",
            "Epoch 66/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2414 - accuracy: 0.9065 - val_loss: 0.9224 - val_accuracy: 0.6897\n",
            "Epoch 67/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2412 - accuracy: 0.9087 - val_loss: 0.9251 - val_accuracy: 0.6897\n",
            "Epoch 68/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2404 - accuracy: 0.9065 - val_loss: 0.9294 - val_accuracy: 0.6897\n",
            "Epoch 69/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2398 - accuracy: 0.9109 - val_loss: 0.9282 - val_accuracy: 0.6897\n",
            "Epoch 70/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2399 - accuracy: 0.9065 - val_loss: 0.9328 - val_accuracy: 0.6897\n",
            "Epoch 71/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2394 - accuracy: 0.9109 - val_loss: 0.9347 - val_accuracy: 0.6983\n",
            "Epoch 72/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2397 - accuracy: 0.9022 - val_loss: 0.9392 - val_accuracy: 0.6897\n",
            "Epoch 73/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2382 - accuracy: 0.9065 - val_loss: 0.9405 - val_accuracy: 0.6897\n",
            "Epoch 74/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2387 - accuracy: 0.9087 - val_loss: 0.9349 - val_accuracy: 0.6983\n",
            "Epoch 75/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2368 - accuracy: 0.9087 - val_loss: 0.9394 - val_accuracy: 0.6983\n",
            "Epoch 76/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2371 - accuracy: 0.9065 - val_loss: 0.9445 - val_accuracy: 0.6897\n",
            "Epoch 77/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2364 - accuracy: 0.9043 - val_loss: 0.9425 - val_accuracy: 0.6897\n",
            "Epoch 78/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2363 - accuracy: 0.9109 - val_loss: 0.9479 - val_accuracy: 0.6810\n",
            "Epoch 79/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2348 - accuracy: 0.9065 - val_loss: 0.9534 - val_accuracy: 0.6897\n",
            "Epoch 80/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2354 - accuracy: 0.9065 - val_loss: 0.9548 - val_accuracy: 0.6810\n",
            "Epoch 81/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2345 - accuracy: 0.9087 - val_loss: 0.9512 - val_accuracy: 0.6897\n",
            "Epoch 82/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2338 - accuracy: 0.9130 - val_loss: 0.9467 - val_accuracy: 0.6983\n",
            "Epoch 83/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2336 - accuracy: 0.9065 - val_loss: 0.9608 - val_accuracy: 0.6897\n",
            "Epoch 84/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2335 - accuracy: 0.9022 - val_loss: 0.9602 - val_accuracy: 0.6724\n",
            "Epoch 85/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2330 - accuracy: 0.9109 - val_loss: 0.9593 - val_accuracy: 0.6724\n",
            "Epoch 86/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2327 - accuracy: 0.9109 - val_loss: 0.9625 - val_accuracy: 0.6724\n",
            "Epoch 87/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2313 - accuracy: 0.9130 - val_loss: 0.9618 - val_accuracy: 0.6810\n",
            "Epoch 88/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2332 - accuracy: 0.9065 - val_loss: 0.9745 - val_accuracy: 0.6810\n",
            "Epoch 89/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2297 - accuracy: 0.9130 - val_loss: 0.9676 - val_accuracy: 0.6638\n",
            "Epoch 90/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2314 - accuracy: 0.9130 - val_loss: 0.9636 - val_accuracy: 0.6724\n",
            "Epoch 91/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2307 - accuracy: 0.9109 - val_loss: 0.9693 - val_accuracy: 0.6638\n",
            "Epoch 92/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2300 - accuracy: 0.9087 - val_loss: 0.9761 - val_accuracy: 0.6724\n",
            "Epoch 93/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2299 - accuracy: 0.9130 - val_loss: 0.9746 - val_accuracy: 0.6810\n",
            "Epoch 94/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2286 - accuracy: 0.9130 - val_loss: 0.9833 - val_accuracy: 0.6724\n",
            "Epoch 95/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2278 - accuracy: 0.9152 - val_loss: 0.9765 - val_accuracy: 0.6638\n",
            "Epoch 96/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2286 - accuracy: 0.9152 - val_loss: 0.9850 - val_accuracy: 0.6724\n",
            "Epoch 97/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2278 - accuracy: 0.9152 - val_loss: 0.9829 - val_accuracy: 0.6638\n",
            "Epoch 98/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2269 - accuracy: 0.9152 - val_loss: 0.9909 - val_accuracy: 0.6724\n",
            "Epoch 99/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2280 - accuracy: 0.9130 - val_loss: 0.9847 - val_accuracy: 0.6724\n",
            "Epoch 100/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2269 - accuracy: 0.9130 - val_loss: 0.9826 - val_accuracy: 0.6724\n",
            "Epoch 101/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2258 - accuracy: 0.9087 - val_loss: 0.9941 - val_accuracy: 0.6724\n",
            "Epoch 102/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2257 - accuracy: 0.9065 - val_loss: 0.9966 - val_accuracy: 0.6724\n",
            "Epoch 103/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2247 - accuracy: 0.9130 - val_loss: 0.9992 - val_accuracy: 0.6724\n",
            "Epoch 104/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2243 - accuracy: 0.9152 - val_loss: 0.9911 - val_accuracy: 0.6724\n",
            "Epoch 105/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2242 - accuracy: 0.9152 - val_loss: 1.0044 - val_accuracy: 0.6724\n",
            "Epoch 106/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2232 - accuracy: 0.9130 - val_loss: 1.0064 - val_accuracy: 0.6724\n",
            "Epoch 107/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2239 - accuracy: 0.9109 - val_loss: 1.0036 - val_accuracy: 0.6810\n",
            "Epoch 108/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2221 - accuracy: 0.9174 - val_loss: 1.0080 - val_accuracy: 0.6724\n",
            "Epoch 109/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2229 - accuracy: 0.9130 - val_loss: 1.0069 - val_accuracy: 0.6724\n",
            "Epoch 110/200\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.2224 - accuracy: 0.9087 - val_loss: 1.0167 - val_accuracy: 0.6724\n",
            "Epoch 111/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2229 - accuracy: 0.9196 - val_loss: 1.0071 - val_accuracy: 0.6724\n",
            "Epoch 112/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2212 - accuracy: 0.9152 - val_loss: 1.0207 - val_accuracy: 0.6810\n",
            "Epoch 113/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2206 - accuracy: 0.9109 - val_loss: 1.0216 - val_accuracy: 0.6810\n",
            "Epoch 114/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2214 - accuracy: 0.9174 - val_loss: 1.0214 - val_accuracy: 0.6810\n",
            "Epoch 115/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2202 - accuracy: 0.9217 - val_loss: 1.0189 - val_accuracy: 0.6724\n",
            "Epoch 116/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2195 - accuracy: 0.9196 - val_loss: 1.0271 - val_accuracy: 0.6810\n",
            "Epoch 117/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2190 - accuracy: 0.9174 - val_loss: 1.0343 - val_accuracy: 0.6810\n",
            "Epoch 118/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2192 - accuracy: 0.9217 - val_loss: 1.0213 - val_accuracy: 0.6810\n",
            "Epoch 119/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2188 - accuracy: 0.9196 - val_loss: 1.0306 - val_accuracy: 0.6810\n",
            "Epoch 120/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2177 - accuracy: 0.9196 - val_loss: 1.0384 - val_accuracy: 0.6810\n",
            "Epoch 121/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2174 - accuracy: 0.9174 - val_loss: 1.0371 - val_accuracy: 0.6810\n",
            "Epoch 122/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2179 - accuracy: 0.9174 - val_loss: 1.0357 - val_accuracy: 0.6810\n",
            "Epoch 123/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2177 - accuracy: 0.9152 - val_loss: 1.0400 - val_accuracy: 0.6810\n",
            "Epoch 124/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2162 - accuracy: 0.9239 - val_loss: 1.0398 - val_accuracy: 0.6810\n",
            "Epoch 125/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2169 - accuracy: 0.9196 - val_loss: 1.0426 - val_accuracy: 0.6724\n",
            "Epoch 126/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2165 - accuracy: 0.9152 - val_loss: 1.0424 - val_accuracy: 0.6810\n",
            "Epoch 127/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2165 - accuracy: 0.9217 - val_loss: 1.0539 - val_accuracy: 0.6810\n",
            "Epoch 128/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2157 - accuracy: 0.9174 - val_loss: 1.0477 - val_accuracy: 0.6810\n",
            "Epoch 129/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2155 - accuracy: 0.9196 - val_loss: 1.0493 - val_accuracy: 0.6810\n",
            "Epoch 130/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2142 - accuracy: 0.9196 - val_loss: 1.0497 - val_accuracy: 0.6810\n",
            "Epoch 131/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2155 - accuracy: 0.9217 - val_loss: 1.0491 - val_accuracy: 0.6724\n",
            "Epoch 132/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2155 - accuracy: 0.9174 - val_loss: 1.0603 - val_accuracy: 0.6810\n",
            "Epoch 133/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2145 - accuracy: 0.9239 - val_loss: 1.0566 - val_accuracy: 0.6810\n",
            "Epoch 134/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2124 - accuracy: 0.9174 - val_loss: 1.0588 - val_accuracy: 0.6810\n",
            "Epoch 135/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2132 - accuracy: 0.9174 - val_loss: 1.0654 - val_accuracy: 0.6810\n",
            "Epoch 136/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2120 - accuracy: 0.9196 - val_loss: 1.0636 - val_accuracy: 0.6810\n",
            "Epoch 137/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2114 - accuracy: 0.9239 - val_loss: 1.0602 - val_accuracy: 0.6724\n",
            "Epoch 138/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2124 - accuracy: 0.9174 - val_loss: 1.0707 - val_accuracy: 0.6810\n",
            "Epoch 139/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2118 - accuracy: 0.9196 - val_loss: 1.0644 - val_accuracy: 0.6810\n",
            "Epoch 140/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2109 - accuracy: 0.9217 - val_loss: 1.0752 - val_accuracy: 0.6810\n",
            "Epoch 141/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2103 - accuracy: 0.9174 - val_loss: 1.0712 - val_accuracy: 0.6810\n",
            "Epoch 142/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2104 - accuracy: 0.9217 - val_loss: 1.0671 - val_accuracy: 0.6810\n",
            "Epoch 143/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2104 - accuracy: 0.9196 - val_loss: 1.0829 - val_accuracy: 0.6810\n",
            "Epoch 144/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2105 - accuracy: 0.9261 - val_loss: 1.0759 - val_accuracy: 0.6810\n",
            "Epoch 145/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2084 - accuracy: 0.9174 - val_loss: 1.0886 - val_accuracy: 0.6810\n",
            "Epoch 146/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2080 - accuracy: 0.9217 - val_loss: 1.0766 - val_accuracy: 0.6810\n",
            "Epoch 147/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2073 - accuracy: 0.9239 - val_loss: 1.0854 - val_accuracy: 0.6810\n",
            "Epoch 148/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2075 - accuracy: 0.9196 - val_loss: 1.0950 - val_accuracy: 0.6810\n",
            "Epoch 149/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2072 - accuracy: 0.9217 - val_loss: 1.0939 - val_accuracy: 0.6810\n",
            "Epoch 150/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2078 - accuracy: 0.9196 - val_loss: 1.0908 - val_accuracy: 0.6810\n",
            "Epoch 151/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2059 - accuracy: 0.9174 - val_loss: 1.0891 - val_accuracy: 0.6724\n",
            "Epoch 152/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2063 - accuracy: 0.9174 - val_loss: 1.0984 - val_accuracy: 0.6810\n",
            "Epoch 153/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2052 - accuracy: 0.9261 - val_loss: 1.0915 - val_accuracy: 0.6724\n",
            "Epoch 154/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2042 - accuracy: 0.9239 - val_loss: 1.1035 - val_accuracy: 0.6724\n",
            "Epoch 155/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2042 - accuracy: 0.9196 - val_loss: 1.1000 - val_accuracy: 0.6724\n",
            "Epoch 156/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2041 - accuracy: 0.9239 - val_loss: 1.1068 - val_accuracy: 0.6810\n",
            "Epoch 157/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2026 - accuracy: 0.9261 - val_loss: 1.1097 - val_accuracy: 0.6638\n",
            "Epoch 158/200\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.2035 - accuracy: 0.9261 - val_loss: 1.1107 - val_accuracy: 0.6638\n",
            "Epoch 159/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2031 - accuracy: 0.9261 - val_loss: 1.1134 - val_accuracy: 0.6638\n",
            "Epoch 160/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2019 - accuracy: 0.9217 - val_loss: 1.1052 - val_accuracy: 0.6552\n",
            "Epoch 161/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2015 - accuracy: 0.9261 - val_loss: 1.1124 - val_accuracy: 0.6466\n",
            "Epoch 162/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2004 - accuracy: 0.9239 - val_loss: 1.1245 - val_accuracy: 0.6466\n",
            "Epoch 163/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2005 - accuracy: 0.9217 - val_loss: 1.1172 - val_accuracy: 0.6552\n",
            "Epoch 164/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.2000 - accuracy: 0.9304 - val_loss: 1.1170 - val_accuracy: 0.6552\n",
            "Epoch 165/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.1999 - accuracy: 0.9261 - val_loss: 1.1204 - val_accuracy: 0.6466\n",
            "Epoch 166/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.1995 - accuracy: 0.9304 - val_loss: 1.1182 - val_accuracy: 0.6552\n",
            "Epoch 167/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.1993 - accuracy: 0.9283 - val_loss: 1.1249 - val_accuracy: 0.6466\n",
            "Epoch 168/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.1988 - accuracy: 0.9348 - val_loss: 1.1288 - val_accuracy: 0.6466\n",
            "Epoch 169/200\n",
            "23/23 [==============================] - 0s 20ms/step - loss: 0.1991 - accuracy: 0.9239 - val_loss: 1.1315 - val_accuracy: 0.6379\n",
            "Epoch 170/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.1973 - accuracy: 0.9261 - val_loss: 1.1298 - val_accuracy: 0.6466\n",
            "Epoch 171/200\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.1978 - accuracy: 0.9304 - val_loss: 1.1276 - val_accuracy: 0.6552\n",
            "Epoch 172/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.1978 - accuracy: 0.9370 - val_loss: 1.1364 - val_accuracy: 0.6466\n",
            "Epoch 173/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.1969 - accuracy: 0.9326 - val_loss: 1.1291 - val_accuracy: 0.6466\n",
            "Epoch 174/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.1964 - accuracy: 0.9283 - val_loss: 1.1374 - val_accuracy: 0.6293\n",
            "Epoch 175/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.1961 - accuracy: 0.9326 - val_loss: 1.1465 - val_accuracy: 0.6466\n",
            "Epoch 176/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.1967 - accuracy: 0.9348 - val_loss: 1.1451 - val_accuracy: 0.6379\n",
            "Epoch 177/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.1965 - accuracy: 0.9326 - val_loss: 1.1511 - val_accuracy: 0.6379\n",
            "Epoch 178/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.1957 - accuracy: 0.9326 - val_loss: 1.1468 - val_accuracy: 0.6466\n",
            "Epoch 179/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.1945 - accuracy: 0.9326 - val_loss: 1.1477 - val_accuracy: 0.6379\n",
            "Epoch 180/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.1951 - accuracy: 0.9348 - val_loss: 1.1580 - val_accuracy: 0.6466\n",
            "Epoch 181/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.1947 - accuracy: 0.9304 - val_loss: 1.1506 - val_accuracy: 0.6379\n",
            "Epoch 182/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.1934 - accuracy: 0.9370 - val_loss: 1.1499 - val_accuracy: 0.6379\n",
            "Epoch 183/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.1928 - accuracy: 0.9370 - val_loss: 1.1531 - val_accuracy: 0.6379\n",
            "Epoch 184/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.1945 - accuracy: 0.9304 - val_loss: 1.1578 - val_accuracy: 0.6379\n",
            "Epoch 185/200\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.1925 - accuracy: 0.9326 - val_loss: 1.1597 - val_accuracy: 0.6379\n",
            "Epoch 186/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.1922 - accuracy: 0.9348 - val_loss: 1.1639 - val_accuracy: 0.6466\n",
            "Epoch 187/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.1927 - accuracy: 0.9326 - val_loss: 1.1675 - val_accuracy: 0.6379\n",
            "Epoch 188/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.1920 - accuracy: 0.9391 - val_loss: 1.1678 - val_accuracy: 0.6207\n",
            "Epoch 189/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.1915 - accuracy: 0.9370 - val_loss: 1.1722 - val_accuracy: 0.6379\n",
            "Epoch 190/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.1904 - accuracy: 0.9326 - val_loss: 1.1751 - val_accuracy: 0.6379\n",
            "Epoch 191/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.1908 - accuracy: 0.9348 - val_loss: 1.1821 - val_accuracy: 0.6379\n",
            "Epoch 192/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.1903 - accuracy: 0.9370 - val_loss: 1.1784 - val_accuracy: 0.6379\n",
            "Epoch 193/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.1900 - accuracy: 0.9370 - val_loss: 1.1909 - val_accuracy: 0.6293\n",
            "Epoch 194/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.1900 - accuracy: 0.9326 - val_loss: 1.1868 - val_accuracy: 0.6379\n",
            "Epoch 195/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.1887 - accuracy: 0.9348 - val_loss: 1.1863 - val_accuracy: 0.6379\n",
            "Epoch 196/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.1889 - accuracy: 0.9370 - val_loss: 1.1868 - val_accuracy: 0.6379\n",
            "Epoch 197/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.1882 - accuracy: 0.9326 - val_loss: 1.1986 - val_accuracy: 0.6379\n",
            "Epoch 198/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.1883 - accuracy: 0.9370 - val_loss: 1.1998 - val_accuracy: 0.6379\n",
            "Epoch 199/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.1885 - accuracy: 0.9435 - val_loss: 1.2015 - val_accuracy: 0.6379\n",
            "Epoch 200/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.1875 - accuracy: 0.9370 - val_loss: 1.2038 - val_accuracy: 0.6379\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhnwPu07twTa",
        "outputId": "d1bc4db8-4e1e-44c1-a7a7-29551be257db"
      },
      "source": [
        "acc = model2.evaluate(X_test, y_test)\r\n",
        "acc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6448 - accuracy: 0.6679\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6576449275016785, 0.6510416865348816]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bb2LtziKzriU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}