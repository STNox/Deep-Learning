{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "05_와인 베스트 모델.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGzxquT9ZHIL"
      },
      "source": [
        "# 와인 베스트 모델 찾기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzou7tDeZA1Q"
      },
      "source": [
        "import numpy as np\r\n",
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FeKaDdSRZOBC"
      },
      "source": [
        "seed = 2021\r\n",
        "np.random.seed(seed)\r\n",
        "tf.random.set_seed(seed)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 93
        },
        "id": "rTshzTg2ZTXD",
        "outputId": "1653b3c9-3d53-4248-9eb1-23778916d0d9"
      },
      "source": [
        "import pandas as pd\r\n",
        "from google.colab import files\r\n",
        "uploaded = files.upload()\r\n",
        "filename = list(uploaded.keys())[0]\r\n",
        "filename"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e9c3ae2e-9429-4287-b805-f7886e638635\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e9c3ae2e-9429-4287-b805-f7886e638635\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving wine.csv to wine (2).csv\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'wine.csv'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "jUqdT-tIZjpc",
        "outputId": "5914ee36-64e2-4325-e103-f2a63a54dc6c"
      },
      "source": [
        "df = pd.read_csv(filename, header=None)\r\n",
        "df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.076</td>\n",
              "      <td>11.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.9978</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.4</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.6</td>\n",
              "      <td>0.098</td>\n",
              "      <td>25.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>0.9968</td>\n",
              "      <td>3.20</td>\n",
              "      <td>0.68</td>\n",
              "      <td>9.8</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.04</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0.092</td>\n",
              "      <td>15.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>0.9970</td>\n",
              "      <td>3.26</td>\n",
              "      <td>0.65</td>\n",
              "      <td>9.8</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.2</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.56</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.075</td>\n",
              "      <td>17.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>0.9980</td>\n",
              "      <td>3.16</td>\n",
              "      <td>0.58</td>\n",
              "      <td>9.8</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.076</td>\n",
              "      <td>11.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.9978</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.4</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     0     1     2    3      4     5     6       7     8     9    10  11  12\n",
              "0   7.4  0.70  0.00  1.9  0.076  11.0  34.0  0.9978  3.51  0.56  9.4   5   1\n",
              "1   7.8  0.88  0.00  2.6  0.098  25.0  67.0  0.9968  3.20  0.68  9.8   5   1\n",
              "2   7.8  0.76  0.04  2.3  0.092  15.0  54.0  0.9970  3.26  0.65  9.8   5   1\n",
              "3  11.2  0.28  0.56  1.9  0.075  17.0  60.0  0.9980  3.16  0.58  9.8   6   1\n",
              "4   7.4  0.70  0.00  1.9  0.076  11.0  34.0  0.9978  3.51  0.56  9.4   5   1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOIACpZvZtLq",
        "outputId": "67d40b37-75d9-4401-f44a-3d3b4807a831"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(df.iloc[:, :-1].values, df.iloc[:, -1].values, stratify=df.iloc[:, -1].values, random_state=seed)\r\n",
        "X_train.shape, X_test.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((4872, 12), (1625, 12))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVSpSImga-xS"
      },
      "source": [
        "### 모델 정의/설정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOiFynuLamd6"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras.layers import Dense"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZB6sq8XnbJfv",
        "outputId": "16cb90c5-7e74-4238-cdea-7fbc1738e4db"
      },
      "source": [
        "model = Sequential([\r\n",
        "                    Dense(30, input_dim=12, activation='relu'),\r\n",
        "                    Dense(12, activation='relu'),\r\n",
        "                    Dense(8, activation='relu'),\r\n",
        "                    Dense(1, activation='sigmoid')\r\n",
        "])\r\n",
        "model.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 30)                390       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 12)                372       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 8)                 104       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 875\n",
            "Trainable params: 875\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAfTBJM0bhKH"
      },
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iESVutJvcC0k"
      },
      "source": [
        "### 모델 저장 관련 환경설정, 자동중단"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scivkISscCKj"
      },
      "source": [
        "import os\r\n",
        "MODEL_DIR = './model/'\r\n",
        "if not os.path.exists(MODEL_DIR):\r\n",
        "  os.mkdir(MODEL_DIR)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pp4R74a7cPdA",
        "outputId": "d340f7b5-fadc-40b3-eac8-f2923599a6c8"
      },
      "source": [
        "!ls -l"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 1076\n",
            "drwxr-xr-x 2 root root   4096 Feb 10 01:44  model\n",
            "drwxr-xr-x 1 root root   4096 Feb  4 15:26  sample_data\n",
            "-rw-r--r-- 1 root root 361279 Feb 10 01:44 'wine (1).csv'\n",
            "-rw-r--r-- 1 root root 361279 Feb 10 01:46 'wine (2).csv'\n",
            "-rw-r--r-- 1 root root 361279 Feb 10 01:26  wine.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caU8m5zTcRIK"
      },
      "source": [
        "# 모델 저장 조건 설정\r\n",
        "modelpath = MODEL_DIR + \"best{epoch:03d}-{val_loss:.4f}.hdf5\""
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGT0X-Qhclv9"
      },
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\r\n",
        "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True)\r\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=30)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzOnMqjUdbbW"
      },
      "source": [
        "### 모델 학습 및 저장"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7Xwo0VFdalE",
        "outputId": "80e3c4d7-b376-42e8-ac55-d02ec2d6c5eb"
      },
      "source": [
        "history = model.fit(X_train, y_train, validation_split=0.2, epochs=500, batch_size=200, verbose=0, callbacks=[checkpointer, early_stopping])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.41822, saving model to ./model/best001-0.4182.hdf5\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.41822 to 0.28623, saving model to ./model/best002-0.2862.hdf5\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.28623 to 0.24628, saving model to ./model/best003-0.2463.hdf5\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.24628 to 0.22050, saving model to ./model/best004-0.2205.hdf5\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.22050 to 0.20001, saving model to ./model/best005-0.2000.hdf5\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.20001 to 0.19209, saving model to ./model/best006-0.1921.hdf5\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.19209 to 0.18488, saving model to ./model/best007-0.1849.hdf5\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.18488 to 0.18360, saving model to ./model/best008-0.1836.hdf5\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.18360 to 0.17670, saving model to ./model/best009-0.1767.hdf5\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.17670 to 0.17541, saving model to ./model/best010-0.1754.hdf5\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.17541 to 0.17388, saving model to ./model/best011-0.1739.hdf5\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.17388 to 0.16688, saving model to ./model/best012-0.1669.hdf5\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.16688 to 0.16274, saving model to ./model/best013-0.1627.hdf5\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.16274 to 0.16253, saving model to ./model/best014-0.1625.hdf5\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.16253 to 0.15751, saving model to ./model/best015-0.1575.hdf5\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.15751 to 0.15722, saving model to ./model/best016-0.1572.hdf5\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.15722 to 0.15508, saving model to ./model/best017-0.1551.hdf5\n",
            "\n",
            "Epoch 00018: val_loss improved from 0.15508 to 0.15077, saving model to ./model/best018-0.1508.hdf5\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.15077 to 0.14924, saving model to ./model/best019-0.1492.hdf5\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.14924 to 0.14708, saving model to ./model/best020-0.1471.hdf5\n",
            "\n",
            "Epoch 00021: val_loss improved from 0.14708 to 0.14639, saving model to ./model/best021-0.1464.hdf5\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.14639\n",
            "\n",
            "Epoch 00023: val_loss improved from 0.14639 to 0.13917, saving model to ./model/best023-0.1392.hdf5\n",
            "\n",
            "Epoch 00024: val_loss improved from 0.13917 to 0.13772, saving model to ./model/best024-0.1377.hdf5\n",
            "\n",
            "Epoch 00025: val_loss improved from 0.13772 to 0.13441, saving model to ./model/best025-0.1344.hdf5\n",
            "\n",
            "Epoch 00026: val_loss improved from 0.13441 to 0.12824, saving model to ./model/best026-0.1282.hdf5\n",
            "\n",
            "Epoch 00027: val_loss improved from 0.12824 to 0.12421, saving model to ./model/best027-0.1242.hdf5\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.12421\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.12421\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.12421\n",
            "\n",
            "Epoch 00031: val_loss improved from 0.12421 to 0.11388, saving model to ./model/best031-0.1139.hdf5\n",
            "\n",
            "Epoch 00032: val_loss improved from 0.11388 to 0.10927, saving model to ./model/best032-0.1093.hdf5\n",
            "\n",
            "Epoch 00033: val_loss improved from 0.10927 to 0.10697, saving model to ./model/best033-0.1070.hdf5\n",
            "\n",
            "Epoch 00034: val_loss improved from 0.10697 to 0.10434, saving model to ./model/best034-0.1043.hdf5\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.10434\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.10434\n",
            "\n",
            "Epoch 00037: val_loss improved from 0.10434 to 0.10397, saving model to ./model/best037-0.1040.hdf5\n",
            "\n",
            "Epoch 00038: val_loss improved from 0.10397 to 0.10336, saving model to ./model/best038-0.1034.hdf5\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.10336\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.10336\n",
            "\n",
            "Epoch 00041: val_loss improved from 0.10336 to 0.09690, saving model to ./model/best041-0.0969.hdf5\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.09690\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.09690\n",
            "\n",
            "Epoch 00044: val_loss improved from 0.09690 to 0.09461, saving model to ./model/best044-0.0946.hdf5\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.09461\n",
            "\n",
            "Epoch 00046: val_loss improved from 0.09461 to 0.09151, saving model to ./model/best046-0.0915.hdf5\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.09151\n",
            "\n",
            "Epoch 00048: val_loss improved from 0.09151 to 0.09145, saving model to ./model/best048-0.0914.hdf5\n",
            "\n",
            "Epoch 00049: val_loss improved from 0.09145 to 0.08915, saving model to ./model/best049-0.0891.hdf5\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.08915\n",
            "\n",
            "Epoch 00051: val_loss did not improve from 0.08915\n",
            "\n",
            "Epoch 00052: val_loss improved from 0.08915 to 0.08568, saving model to ./model/best052-0.0857.hdf5\n",
            "\n",
            "Epoch 00053: val_loss improved from 0.08568 to 0.08503, saving model to ./model/best053-0.0850.hdf5\n",
            "\n",
            "Epoch 00054: val_loss improved from 0.08503 to 0.08463, saving model to ./model/best054-0.0846.hdf5\n",
            "\n",
            "Epoch 00055: val_loss did not improve from 0.08463\n",
            "\n",
            "Epoch 00056: val_loss improved from 0.08463 to 0.08397, saving model to ./model/best056-0.0840.hdf5\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 0.08397\n",
            "\n",
            "Epoch 00058: val_loss improved from 0.08397 to 0.08135, saving model to ./model/best058-0.0813.hdf5\n",
            "\n",
            "Epoch 00059: val_loss improved from 0.08135 to 0.07926, saving model to ./model/best059-0.0793.hdf5\n",
            "\n",
            "Epoch 00060: val_loss did not improve from 0.07926\n",
            "\n",
            "Epoch 00061: val_loss did not improve from 0.07926\n",
            "\n",
            "Epoch 00062: val_loss improved from 0.07926 to 0.07745, saving model to ./model/best062-0.0774.hdf5\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 0.07745\n",
            "\n",
            "Epoch 00064: val_loss did not improve from 0.07745\n",
            "\n",
            "Epoch 00065: val_loss improved from 0.07745 to 0.07615, saving model to ./model/best065-0.0761.hdf5\n",
            "\n",
            "Epoch 00066: val_loss did not improve from 0.07615\n",
            "\n",
            "Epoch 00067: val_loss did not improve from 0.07615\n",
            "\n",
            "Epoch 00068: val_loss did not improve from 0.07615\n",
            "\n",
            "Epoch 00069: val_loss improved from 0.07615 to 0.07327, saving model to ./model/best069-0.0733.hdf5\n",
            "\n",
            "Epoch 00070: val_loss did not improve from 0.07327\n",
            "\n",
            "Epoch 00071: val_loss did not improve from 0.07327\n",
            "\n",
            "Epoch 00072: val_loss improved from 0.07327 to 0.07200, saving model to ./model/best072-0.0720.hdf5\n",
            "\n",
            "Epoch 00073: val_loss did not improve from 0.07200\n",
            "\n",
            "Epoch 00074: val_loss improved from 0.07200 to 0.07014, saving model to ./model/best074-0.0701.hdf5\n",
            "\n",
            "Epoch 00075: val_loss did not improve from 0.07014\n",
            "\n",
            "Epoch 00076: val_loss improved from 0.07014 to 0.06874, saving model to ./model/best076-0.0687.hdf5\n",
            "\n",
            "Epoch 00077: val_loss did not improve from 0.06874\n",
            "\n",
            "Epoch 00078: val_loss did not improve from 0.06874\n",
            "\n",
            "Epoch 00079: val_loss did not improve from 0.06874\n",
            "\n",
            "Epoch 00080: val_loss did not improve from 0.06874\n",
            "\n",
            "Epoch 00081: val_loss improved from 0.06874 to 0.06720, saving model to ./model/best081-0.0672.hdf5\n",
            "\n",
            "Epoch 00082: val_loss did not improve from 0.06720\n",
            "\n",
            "Epoch 00083: val_loss improved from 0.06720 to 0.06626, saving model to ./model/best083-0.0663.hdf5\n",
            "\n",
            "Epoch 00084: val_loss did not improve from 0.06626\n",
            "\n",
            "Epoch 00085: val_loss improved from 0.06626 to 0.06570, saving model to ./model/best085-0.0657.hdf5\n",
            "\n",
            "Epoch 00086: val_loss did not improve from 0.06570\n",
            "\n",
            "Epoch 00087: val_loss did not improve from 0.06570\n",
            "\n",
            "Epoch 00088: val_loss did not improve from 0.06570\n",
            "\n",
            "Epoch 00089: val_loss improved from 0.06570 to 0.06368, saving model to ./model/best089-0.0637.hdf5\n",
            "\n",
            "Epoch 00090: val_loss did not improve from 0.06368\n",
            "\n",
            "Epoch 00091: val_loss did not improve from 0.06368\n",
            "\n",
            "Epoch 00092: val_loss did not improve from 0.06368\n",
            "\n",
            "Epoch 00093: val_loss did not improve from 0.06368\n",
            "\n",
            "Epoch 00094: val_loss did not improve from 0.06368\n",
            "\n",
            "Epoch 00095: val_loss did not improve from 0.06368\n",
            "\n",
            "Epoch 00096: val_loss did not improve from 0.06368\n",
            "\n",
            "Epoch 00097: val_loss did not improve from 0.06368\n",
            "\n",
            "Epoch 00098: val_loss improved from 0.06368 to 0.06190, saving model to ./model/best098-0.0619.hdf5\n",
            "\n",
            "Epoch 00099: val_loss did not improve from 0.06190\n",
            "\n",
            "Epoch 00100: val_loss did not improve from 0.06190\n",
            "\n",
            "Epoch 00101: val_loss improved from 0.06190 to 0.06155, saving model to ./model/best101-0.0615.hdf5\n",
            "\n",
            "Epoch 00102: val_loss did not improve from 0.06155\n",
            "\n",
            "Epoch 00103: val_loss did not improve from 0.06155\n",
            "\n",
            "Epoch 00104: val_loss did not improve from 0.06155\n",
            "\n",
            "Epoch 00105: val_loss improved from 0.06155 to 0.06092, saving model to ./model/best105-0.0609.hdf5\n",
            "\n",
            "Epoch 00106: val_loss did not improve from 0.06092\n",
            "\n",
            "Epoch 00107: val_loss did not improve from 0.06092\n",
            "\n",
            "Epoch 00108: val_loss did not improve from 0.06092\n",
            "\n",
            "Epoch 00109: val_loss improved from 0.06092 to 0.05978, saving model to ./model/best109-0.0598.hdf5\n",
            "\n",
            "Epoch 00110: val_loss improved from 0.05978 to 0.05942, saving model to ./model/best110-0.0594.hdf5\n",
            "\n",
            "Epoch 00111: val_loss did not improve from 0.05942\n",
            "\n",
            "Epoch 00112: val_loss did not improve from 0.05942\n",
            "\n",
            "Epoch 00113: val_loss did not improve from 0.05942\n",
            "\n",
            "Epoch 00114: val_loss did not improve from 0.05942\n",
            "\n",
            "Epoch 00115: val_loss did not improve from 0.05942\n",
            "\n",
            "Epoch 00116: val_loss did not improve from 0.05942\n",
            "\n",
            "Epoch 00117: val_loss did not improve from 0.05942\n",
            "\n",
            "Epoch 00118: val_loss did not improve from 0.05942\n",
            "\n",
            "Epoch 00119: val_loss did not improve from 0.05942\n",
            "\n",
            "Epoch 00120: val_loss did not improve from 0.05942\n",
            "\n",
            "Epoch 00121: val_loss improved from 0.05942 to 0.05878, saving model to ./model/best121-0.0588.hdf5\n",
            "\n",
            "Epoch 00122: val_loss improved from 0.05878 to 0.05850, saving model to ./model/best122-0.0585.hdf5\n",
            "\n",
            "Epoch 00123: val_loss did not improve from 0.05850\n",
            "\n",
            "Epoch 00124: val_loss improved from 0.05850 to 0.05746, saving model to ./model/best124-0.0575.hdf5\n",
            "\n",
            "Epoch 00125: val_loss did not improve from 0.05746\n",
            "\n",
            "Epoch 00126: val_loss did not improve from 0.05746\n",
            "\n",
            "Epoch 00127: val_loss did not improve from 0.05746\n",
            "\n",
            "Epoch 00128: val_loss did not improve from 0.05746\n",
            "\n",
            "Epoch 00129: val_loss improved from 0.05746 to 0.05745, saving model to ./model/best129-0.0575.hdf5\n",
            "\n",
            "Epoch 00130: val_loss did not improve from 0.05745\n",
            "\n",
            "Epoch 00131: val_loss improved from 0.05745 to 0.05711, saving model to ./model/best131-0.0571.hdf5\n",
            "\n",
            "Epoch 00132: val_loss did not improve from 0.05711\n",
            "\n",
            "Epoch 00133: val_loss did not improve from 0.05711\n",
            "\n",
            "Epoch 00134: val_loss improved from 0.05711 to 0.05606, saving model to ./model/best134-0.0561.hdf5\n",
            "\n",
            "Epoch 00135: val_loss did not improve from 0.05606\n",
            "\n",
            "Epoch 00136: val_loss did not improve from 0.05606\n",
            "\n",
            "Epoch 00137: val_loss did not improve from 0.05606\n",
            "\n",
            "Epoch 00138: val_loss did not improve from 0.05606\n",
            "\n",
            "Epoch 00139: val_loss improved from 0.05606 to 0.05559, saving model to ./model/best139-0.0556.hdf5\n",
            "\n",
            "Epoch 00140: val_loss did not improve from 0.05559\n",
            "\n",
            "Epoch 00141: val_loss did not improve from 0.05559\n",
            "\n",
            "Epoch 00142: val_loss did not improve from 0.05559\n",
            "\n",
            "Epoch 00143: val_loss did not improve from 0.05559\n",
            "\n",
            "Epoch 00144: val_loss did not improve from 0.05559\n",
            "\n",
            "Epoch 00145: val_loss did not improve from 0.05559\n",
            "\n",
            "Epoch 00146: val_loss did not improve from 0.05559\n",
            "\n",
            "Epoch 00147: val_loss did not improve from 0.05559\n",
            "\n",
            "Epoch 00148: val_loss did not improve from 0.05559\n",
            "\n",
            "Epoch 00149: val_loss did not improve from 0.05559\n",
            "\n",
            "Epoch 00150: val_loss did not improve from 0.05559\n",
            "\n",
            "Epoch 00151: val_loss did not improve from 0.05559\n",
            "\n",
            "Epoch 00152: val_loss did not improve from 0.05559\n",
            "\n",
            "Epoch 00153: val_loss did not improve from 0.05559\n",
            "\n",
            "Epoch 00154: val_loss did not improve from 0.05559\n",
            "\n",
            "Epoch 00155: val_loss did not improve from 0.05559\n",
            "\n",
            "Epoch 00156: val_loss improved from 0.05559 to 0.05528, saving model to ./model/best156-0.0553.hdf5\n",
            "\n",
            "Epoch 00157: val_loss did not improve from 0.05528\n",
            "\n",
            "Epoch 00158: val_loss did not improve from 0.05528\n",
            "\n",
            "Epoch 00159: val_loss did not improve from 0.05528\n",
            "\n",
            "Epoch 00160: val_loss did not improve from 0.05528\n",
            "\n",
            "Epoch 00161: val_loss did not improve from 0.05528\n",
            "\n",
            "Epoch 00162: val_loss did not improve from 0.05528\n",
            "\n",
            "Epoch 00163: val_loss did not improve from 0.05528\n",
            "\n",
            "Epoch 00164: val_loss did not improve from 0.05528\n",
            "\n",
            "Epoch 00165: val_loss did not improve from 0.05528\n",
            "\n",
            "Epoch 00166: val_loss improved from 0.05528 to 0.05464, saving model to ./model/best166-0.0546.hdf5\n",
            "\n",
            "Epoch 00167: val_loss did not improve from 0.05464\n",
            "\n",
            "Epoch 00168: val_loss did not improve from 0.05464\n",
            "\n",
            "Epoch 00169: val_loss did not improve from 0.05464\n",
            "\n",
            "Epoch 00170: val_loss did not improve from 0.05464\n",
            "\n",
            "Epoch 00171: val_loss did not improve from 0.05464\n",
            "\n",
            "Epoch 00172: val_loss did not improve from 0.05464\n",
            "\n",
            "Epoch 00173: val_loss did not improve from 0.05464\n",
            "\n",
            "Epoch 00174: val_loss did not improve from 0.05464\n",
            "\n",
            "Epoch 00175: val_loss did not improve from 0.05464\n",
            "\n",
            "Epoch 00176: val_loss did not improve from 0.05464\n",
            "\n",
            "Epoch 00177: val_loss did not improve from 0.05464\n",
            "\n",
            "Epoch 00178: val_loss did not improve from 0.05464\n",
            "\n",
            "Epoch 00179: val_loss improved from 0.05464 to 0.05425, saving model to ./model/best179-0.0543.hdf5\n",
            "\n",
            "Epoch 00180: val_loss did not improve from 0.05425\n",
            "\n",
            "Epoch 00181: val_loss improved from 0.05425 to 0.05305, saving model to ./model/best181-0.0531.hdf5\n",
            "\n",
            "Epoch 00182: val_loss did not improve from 0.05305\n",
            "\n",
            "Epoch 00183: val_loss did not improve from 0.05305\n",
            "\n",
            "Epoch 00184: val_loss did not improve from 0.05305\n",
            "\n",
            "Epoch 00185: val_loss did not improve from 0.05305\n",
            "\n",
            "Epoch 00186: val_loss did not improve from 0.05305\n",
            "\n",
            "Epoch 00187: val_loss did not improve from 0.05305\n",
            "\n",
            "Epoch 00188: val_loss did not improve from 0.05305\n",
            "\n",
            "Epoch 00189: val_loss did not improve from 0.05305\n",
            "\n",
            "Epoch 00190: val_loss did not improve from 0.05305\n",
            "\n",
            "Epoch 00191: val_loss did not improve from 0.05305\n",
            "\n",
            "Epoch 00192: val_loss did not improve from 0.05305\n",
            "\n",
            "Epoch 00193: val_loss did not improve from 0.05305\n",
            "\n",
            "Epoch 00194: val_loss did not improve from 0.05305\n",
            "\n",
            "Epoch 00195: val_loss did not improve from 0.05305\n",
            "\n",
            "Epoch 00196: val_loss improved from 0.05305 to 0.05303, saving model to ./model/best196-0.0530.hdf5\n",
            "\n",
            "Epoch 00197: val_loss did not improve from 0.05303\n",
            "\n",
            "Epoch 00198: val_loss did not improve from 0.05303\n",
            "\n",
            "Epoch 00199: val_loss did not improve from 0.05303\n",
            "\n",
            "Epoch 00200: val_loss did not improve from 0.05303\n",
            "\n",
            "Epoch 00201: val_loss did not improve from 0.05303\n",
            "\n",
            "Epoch 00202: val_loss did not improve from 0.05303\n",
            "\n",
            "Epoch 00203: val_loss did not improve from 0.05303\n",
            "\n",
            "Epoch 00204: val_loss did not improve from 0.05303\n",
            "\n",
            "Epoch 00205: val_loss did not improve from 0.05303\n",
            "\n",
            "Epoch 00206: val_loss did not improve from 0.05303\n",
            "\n",
            "Epoch 00207: val_loss did not improve from 0.05303\n",
            "\n",
            "Epoch 00208: val_loss did not improve from 0.05303\n",
            "\n",
            "Epoch 00209: val_loss did not improve from 0.05303\n",
            "\n",
            "Epoch 00210: val_loss did not improve from 0.05303\n",
            "\n",
            "Epoch 00211: val_loss did not improve from 0.05303\n",
            "\n",
            "Epoch 00212: val_loss did not improve from 0.05303\n",
            "\n",
            "Epoch 00213: val_loss improved from 0.05303 to 0.05217, saving model to ./model/best213-0.0522.hdf5\n",
            "\n",
            "Epoch 00214: val_loss did not improve from 0.05217\n",
            "\n",
            "Epoch 00215: val_loss improved from 0.05217 to 0.05214, saving model to ./model/best215-0.0521.hdf5\n",
            "\n",
            "Epoch 00216: val_loss did not improve from 0.05214\n",
            "\n",
            "Epoch 00217: val_loss did not improve from 0.05214\n",
            "\n",
            "Epoch 00218: val_loss did not improve from 0.05214\n",
            "\n",
            "Epoch 00219: val_loss did not improve from 0.05214\n",
            "\n",
            "Epoch 00220: val_loss improved from 0.05214 to 0.05178, saving model to ./model/best220-0.0518.hdf5\n",
            "\n",
            "Epoch 00221: val_loss did not improve from 0.05178\n",
            "\n",
            "Epoch 00222: val_loss did not improve from 0.05178\n",
            "\n",
            "Epoch 00223: val_loss did not improve from 0.05178\n",
            "\n",
            "Epoch 00224: val_loss did not improve from 0.05178\n",
            "\n",
            "Epoch 00225: val_loss did not improve from 0.05178\n",
            "\n",
            "Epoch 00226: val_loss did not improve from 0.05178\n",
            "\n",
            "Epoch 00227: val_loss did not improve from 0.05178\n",
            "\n",
            "Epoch 00228: val_loss did not improve from 0.05178\n",
            "\n",
            "Epoch 00229: val_loss did not improve from 0.05178\n",
            "\n",
            "Epoch 00230: val_loss did not improve from 0.05178\n",
            "\n",
            "Epoch 00231: val_loss did not improve from 0.05178\n",
            "\n",
            "Epoch 00232: val_loss did not improve from 0.05178\n",
            "\n",
            "Epoch 00233: val_loss did not improve from 0.05178\n",
            "\n",
            "Epoch 00234: val_loss did not improve from 0.05178\n",
            "\n",
            "Epoch 00235: val_loss did not improve from 0.05178\n",
            "\n",
            "Epoch 00236: val_loss did not improve from 0.05178\n",
            "\n",
            "Epoch 00237: val_loss did not improve from 0.05178\n",
            "\n",
            "Epoch 00238: val_loss did not improve from 0.05178\n",
            "\n",
            "Epoch 00239: val_loss did not improve from 0.05178\n",
            "\n",
            "Epoch 00240: val_loss improved from 0.05178 to 0.05167, saving model to ./model/best240-0.0517.hdf5\n",
            "\n",
            "Epoch 00241: val_loss did not improve from 0.05167\n",
            "\n",
            "Epoch 00242: val_loss did not improve from 0.05167\n",
            "\n",
            "Epoch 00243: val_loss did not improve from 0.05167\n",
            "\n",
            "Epoch 00244: val_loss did not improve from 0.05167\n",
            "\n",
            "Epoch 00245: val_loss did not improve from 0.05167\n",
            "\n",
            "Epoch 00246: val_loss improved from 0.05167 to 0.05128, saving model to ./model/best246-0.0513.hdf5\n",
            "\n",
            "Epoch 00247: val_loss did not improve from 0.05128\n",
            "\n",
            "Epoch 00248: val_loss did not improve from 0.05128\n",
            "\n",
            "Epoch 00249: val_loss did not improve from 0.05128\n",
            "\n",
            "Epoch 00250: val_loss did not improve from 0.05128\n",
            "\n",
            "Epoch 00251: val_loss did not improve from 0.05128\n",
            "\n",
            "Epoch 00252: val_loss did not improve from 0.05128\n",
            "\n",
            "Epoch 00253: val_loss did not improve from 0.05128\n",
            "\n",
            "Epoch 00254: val_loss did not improve from 0.05128\n",
            "\n",
            "Epoch 00255: val_loss did not improve from 0.05128\n",
            "\n",
            "Epoch 00256: val_loss did not improve from 0.05128\n",
            "\n",
            "Epoch 00257: val_loss did not improve from 0.05128\n",
            "\n",
            "Epoch 00258: val_loss did not improve from 0.05128\n",
            "\n",
            "Epoch 00259: val_loss did not improve from 0.05128\n",
            "\n",
            "Epoch 00260: val_loss did not improve from 0.05128\n",
            "\n",
            "Epoch 00261: val_loss did not improve from 0.05128\n",
            "\n",
            "Epoch 00262: val_loss did not improve from 0.05128\n",
            "\n",
            "Epoch 00263: val_loss did not improve from 0.05128\n",
            "\n",
            "Epoch 00264: val_loss did not improve from 0.05128\n",
            "\n",
            "Epoch 00265: val_loss did not improve from 0.05128\n",
            "\n",
            "Epoch 00266: val_loss did not improve from 0.05128\n",
            "\n",
            "Epoch 00267: val_loss did not improve from 0.05128\n",
            "\n",
            "Epoch 00268: val_loss did not improve from 0.05128\n",
            "\n",
            "Epoch 00269: val_loss did not improve from 0.05128\n",
            "\n",
            "Epoch 00270: val_loss did not improve from 0.05128\n",
            "\n",
            "Epoch 00271: val_loss did not improve from 0.05128\n",
            "\n",
            "Epoch 00272: val_loss did not improve from 0.05128\n",
            "\n",
            "Epoch 00273: val_loss did not improve from 0.05128\n",
            "\n",
            "Epoch 00274: val_loss did not improve from 0.05128\n",
            "\n",
            "Epoch 00275: val_loss did not improve from 0.05128\n",
            "\n",
            "Epoch 00276: val_loss did not improve from 0.05128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqhq-I8LeXGa"
      },
      "source": [
        "### 잘못된 평가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhtAVDNGdyqr",
        "outputId": "a7cdcee8-19f9-40cb-9911-4f00fb51b5a7"
      },
      "source": [
        "acc = model.evaluate(X_test, y_test)\r\n",
        "print(f'Accuracy: {acc[1]:.4f}')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "51/51 [==============================] - 0s 1ms/step - loss: 0.0753 - accuracy: 0.9803\n",
            "Accuracy: 0.9803\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s98z5lAcerdt"
      },
      "source": [
        "### 최적 모델로 평가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7i89fDITeqd7",
        "outputId": "f069f34d-e2ca-497f-ba5b-1899865df28e"
      },
      "source": [
        "from tensorflow.keras.models import load_model\r\n",
        "\r\n",
        "best_model = load_model('./model/best246-0.0513.hdf5')\r\n",
        "acc = best_model.evaluate(X_test, y_test)\r\n",
        "print(f'Accuracy: {acc[1]:.4f}')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "51/51 [==============================] - 0s 1ms/step - loss: 0.0732 - accuracy: 0.9778\n",
            "Accuracy: 0.9778\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_ON75a2gqCJ"
      },
      "source": [
        "### 시각화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIyM-LhufzSq"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "%matplotlib inline"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6YNzyquehM1u",
        "outputId": "2f684dfe-039d-47d2-c8b3-6a6fa0890e0b"
      },
      "source": [
        "type(history.history)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-p0AkALdhQID"
      },
      "source": [
        "y_vloss = history.history['val_loss']\r\n",
        "y_acc = history.history['accuracy']\r\n",
        "y_vacc = history.history['val_accuracy']\r\n",
        "y_loss = history.history['loss']"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "id": "LqDmU7mwhhOu",
        "outputId": "8e678491-700e-48de-c61b-9399d603d96d"
      },
      "source": [
        "x_len = np.arange(len(y_acc))\r\n",
        "plt.figure(figsize=(12, 8))\r\n",
        "plt.plot(x_len, y_loss, \"o\", c='red', markersize=2, label='loss')\r\n",
        "plt.plot(x_len, y_vacc, \"o\", c='blue', markersize=2, label='val_accuracy')\r\n",
        "plt.plot(x_len, y_vloss, \"o\", c='orange', markersize=2, label='val_loss')\r\n",
        "plt.plot(x_len, y_acc, \"o\", c='green', markersize=2, label='accuracy')\r\n",
        "plt.legend()\r\n",
        "plt.show()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIpwORllipLJ"
      },
      "source": [
        ""
      ],
      "execution_count": 19,
      "outputs": []
    }
  ]
}